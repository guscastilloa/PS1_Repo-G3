---
title: 'Problem Set 1: Predicting Income'
subtitle: 'Big Data y Machine Learning para Economía Aplicada'
author:  
        - Gustavo Adolfo Castillo Álvarez (201812166), 
        - Alexander Almeida Ramírez (202225165), 
        - Jorge Luis Congacha Yunda (201920042) y 
        - Jaime Orlando Buitrago González (200612390)
date: "03 de marzo de 2024"
fontsize: 11pt
geometry: margin=1in
documentclass: article
papersize: letter
lang: es

header-includes:
    - \usepackage[utf8]{inputenc}
    - \usepackage{floatrow}
    - \floatsetup[figure]{capposition=top}
    
output: 
  pdf_document:
    number_sections: true
    fig_width: 3
    fig_height: 2
    fig_caption: true

bibliography: References.bib  
---

```{r setup, include=FALSE}
require(here)
knitr::opts_chunk$set(echo = TRUE)
#source("../scripts/00_packages.R", local = knitr::knit_global())
library(ggplot2)
here::set_here(path = "../")
source(here("scripts","00_packages.R"), local = knitr::knit_global())
```

```{r prepare_data, echo=FALSE}
db <- arrow::read_parquet("../stores/geih.parquet")
clean_variables <- function(df){
  out_df <- df %>% mutate(
    woman=1-sex,
    woman=factor(woman, levels=c(0,1),labels=c('Hombre','Mujer')),
    maxEducLevel=factor(
      maxEducLevel,levels=1:7),
    uid=paste0(directorio,secuencia_p,orden),
    oficio=factor(oficio, levels=as.double(names(table(db$oficio))))
    )
  out_df
  }

db <- clean_variables(db)
```


# Introducción

Entre 1991 y 2019, el recaudo del impuesto a la renta aumentó en 7,1 puntos porcentuales (p.p.) dentro de la estructura tributaria de América Latina y el Caribe, consolidándose como la segunda fuente de ingresos (26,6\%), después de los impuestos generales sobre bienes y servicios [@cepal]. En contraste, para el último año, Colombia se encontró por encima del promedio de sus pares regionales, pues el impuesto a la renta representó el 32,3\% de su estructura tributaria; sin embargo, al compararla carga la tributaria de este impuesto, Colombia está lejos del grupo de países más desarrollados del cual hace parte, pues la renta representa el 6,4% del PIB, un valor lejano del promedio de la OCDE (34\%).

Más aún para el 2019, el recaudo del impuesto de renta de las personas correspondió a tan sólo al 1,3\% del PIB colombiano según la @cepal. Este nivel de ingresos tributarios es considerablemente bajo y se debe al complejo sistema tributario que permite mayores exensiones y deducciones para quienes tienen ingresos más altos [@undp], al mismo tiempo que las políticas, factores psicológicos, coyunturas económicas y deficiencias administrativas favorecen la evasión y elusión de este impuesto sobre los ingresos [@ex].

Cada reforma tributaria ha intentado mejorar los niveles de recaudo en los últimos años, así mismo, los cambios administrativos en la DIAN también han contribuido a este propósito, buscando un sistema tributario más efciente y progresivo, ya que se cuenta con suficiente información y evidencia para identificar sus principales problemas. No obstante, los comportamientos de las personas, sobre todo aquellos asociados a conductas delictivas (como la elusión y evasión), son más difíciles de identificar ante su carácter ilegal y ético. Instrumentos como el *Machine Learning* (ML) pueden complementar y contribuir a aumentar el recaudo de los impuestos, haciendo visible aquello que las personas buscan ocultar o esconder, es decir, generando predicciones sobre los ingresos de las personas a partir de características individuales, de los hogares, o incluso territoriales.

Así por ejemplo, en Indonesia, a través de modelos predictivos se identificaron potenciales pagos a las deudas por impuestos a partir de los registros administrativos de la autoridad fiscal de ese país [@fw]; en Armenia, se pudieron identificar posibles fraudes fiscales a partir de la información reportada por los compradores y vendedores con herramientas de ML [@bdsn]; o en Brasil, Sao Paulo, se identificaron potenciales pagadores, ingresos, el monto de los impuestos y multas a partir de los registros administrativos de autoridad fiscal del municipio [@ig]. Como revisión de literatura indicativa, más no exahustiva, para países con algunas características similares a las de Colombia, es posible identificar las potencialidades de herramientas como el ML en el recaduo de los impuestos asociados a los ingresos.

Es por tanto, que en este Problem Set busca predecir el ingreso por hora de los y las bogotanas mediante modelos que aprovechan las herramientas del ML, haciendo uso de la principal encuesta de hogares colombiana.  Más específicamente, se utilizó la *Medición de Pobreza Monetaria y Desigualdad* [@geih] del 2018 para Bogotá, un módulo de la *Gran Encuesta Integrada de Hogares* (GEIH) del DANE, la cual no sólo proporciona información sobre el mercado laboral, ingreso de las personas, características socioeconómicas y territoriales, si no a su vez representa una fuente de información confiable en la cual las personas no tienen incentivos a reportar información falsa sobre su ingreso, pues la encuesta es anónima y no tiene una finalidad tributaria.

En este contexto, el presente documento ...(preview of the results an main takeaways)


# Datos

La GEIH es la principal y tal vez más importante encuesta de hogares con la que cuenta Colombia actualmente. Mensualmente, el DANE recolecta información sobre los ingresos y el mercado laboral de una muestra representativa de la población colombiana, de tal manera, que cada mes se obtienen datos sobre el ingreso y mercado laboral para el ámbito nacional, y anualmente para 23 departamentos y Bogotá, sus capitales y áreas metropolitanas, y otros dominios (rural y urbano) [@dane18]. La operación estadística tiene como resultado una base de datos anual de aproximadamente 750 mil observaciones o personas, 230 mil hogares y 30 mil viviendas, la cual permite realizar cálculos y estimaciones sobre la población colombiana.

Aunque la GEIH recolecta información sobre los ingresos y el mercado laboral de la población, se realizan poco más de 150 preguntas a los encuestados que capturan información demográfica, económica y social, de tal manera que se expanden las posibilidades de la encuesta. Es así como esta base de datos también permite caracterizar la migración, micronegocios, la transición entre la educación y el trabajo, y la pobreza monetaria (dentro de los módulos más importantes). Este último módulo es importante para el desarrollo del presente Problem Set, ya que el DANE agrega los ingresos salariales y no salariales per cápita de las unidades de gasto (hogares para simplificar), identificando las personas con ingresos superiores e inferiores a las líneas de pobreza e indigencia definidas en el Comité de Expertos \footnote{Personas o representante de entidades nacionales o de cooperación internacional con la experticia técnica para orientar la operación estadística, cálculos y estimaciones de la pobreza monetaria}. Es así como la GEIH es también la principal fuente de información para calcular la incidencia, brecha y severidad de esta medición del bienestar de la población.

La GEIH y su módulo sobre la *Medición de Pobreza Monetaria y Desigualdad* están disponibles al público en general a través de la Archivo Nacional de Datos (ANDA) del DANE. Sus módulos anonimizados se pueden descargar y unir para la investigación académica, la toma de decisiones o cualquier propósito individual. En este caso, para el Problem Set no se realizó el descargue de la página del DANE, sino se realizó un *web scraping* de la base de datos filtrada para Bogotá, de la página web de Ignacio Sarmiento Barbieri [@geih] como caso práctico de extracción de contenidos de una página web, con un formato estructurado.

En la página web se encuentran 10 tablas en formato HTML, las cuales contienen en total las 32.177 observaciones que componen la muestra de personas para Bogotá de la GEIH para 2018, con 179 variables (21 variables adicionales a las presentes en la base de datos del ANDA). Al encontrarse en un formato estructurado (tabla HTML), se realizó el *web scrpaing* haciendo uso del paquete `RSelenium` de `RStudio`, con el cual se automatiza la consulta de cada una de los 10 hipervínculos de la página web, se identifica la tabla en HTML, se almacena y posteriormente se consolida una sola base de datos con las características anteriormente mencionadas.


De las `r nrow(db)` observaciones, se puede observar la tasa de valores perdidos de las variables de interés:



# Perfiles de salario por edad

# Brechas de ingreso por sexo

# Predicción de salarios

La meta es predecir la brecha salarial del logaritmo del ingreso. Comenzamos estimando el modelo más sencillo de todos, es decir, el modelo univariado:


\begin{equation}
\ln (w) = \beta_1 + \beta_2 Mujer+u
  \label{gap0}
\end{equation}



```{r code_gap, echo=FALSE}
gap0 <- lm('log(y_ingLab_m)~woman', data = db)
gap1 <- lm('log(y_ingLab_m)~age+woman+maxEducLevel+oficio+relab', data = db)
# gap2 <- lm('log(y_ingLab_m)~age+woman+maxEducLevel', data = db)
mean_wage_female <- exp(gap0$coefficients[[1]]+gap0$coefficients[[2]])
```

```{r out_gap0, echo=FALSE, results='asis'}
stargazer(gap0,gap1, 
          title = "Estimando brecha de género",
          type='latex', dep.var.labels = "Ln Salario",
          omit = c('oficio','maxEducLevel'), 
          notes = "Controles: oficio, maxEduclevel", 
          header = FALSE)
```

El coeficiente $\beta_2<0$ indica que las mujeres, en promedio y ceteris praibus, reciben un salario mensual `r exp(gap0$coefficients['womanMujer'][[1]])`  menos ingresos que los hombres. 

## Estimación con FWL

En la primera etapa, *partialling-out*, ejecutamos dos regresiones. Suponiendo que la variable de interés es la dicotómica de $Mujer$, entonces en la primera regresión buscamos estimar `woman~x1+x2+...`, donde las `xi` son todas aquellas demás variables de control para corregir el potencial  sesgo de variable omitida. Luego nos quedamos con los residuales `woman_res`, y ejecutamos una segunda regresión en la que estimemos `log_wage~x1+x2...`, y guardamos estos residuales, `log_wage_res`. 

Finalmente ejecutamos la segunda regresión univariada `log_wage_res~woman_res` y en principio deberíamos obtener el mismo coeficiente de haber ejecutado el modelo completo.



# Referencias bibliográficas

<div id="refs"></div>

# Ejemplos

Para incrustar código y resultados de la consola

```{r cars}
summary(cars)
```

Para incluir ecuaciones

$$
w=f(X)+u
$$

Para incluir gráficas

```{r echo=FALSE, message=FALSE,file="../scripts/Code.R",fig.align = 'center', fig.cap="Título de la gráfica", dpi=300}
```
\begin{center}\footnotesize{Fuente: Cálculos propios a partir de @geih}\end{center}

